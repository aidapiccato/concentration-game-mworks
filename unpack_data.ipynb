{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/Library/Application Support/MWorks/Scripting/Python')\n",
    "from mworks.data import MWKFile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style \n",
    "import pandas as pd\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "style.use('seaborn-notebook')\n",
    "# plt.gca().spines['top'].set_visible(False)\n",
    "# plt.gca().spines['right'].set_visible(False)\n",
    "style.use('seaborn-white')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "username = 'apiccato'\n",
    "# username = 'aidapiccato'\n",
    "dir_path = '/Users/%s/PyCharmProjects/concentration/concentration-game-mworks' % username\n",
    "subject_id = 0\n",
    "subject_fn = '%s/meta/subject_%s.pkl' % (dir_path, subject_id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "## sync times \n",
    "\n",
    "ITI = 1\n",
    "TRIAL_INIT = 2\n",
    "FLIP_CARD_A = 3\n",
    "FLIP_CARD_B = 4\n",
    "FEEDBACK = 5\n",
    "TRIAL_END = 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "def unpack(fn, subject_fn):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param fn: MWorks event stream filename \n",
    "    :param subject_fn: Subject metadata filename\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    def flatten_meta():\n",
    "        \"\"\"\n",
    "        \n",
    "        :return: Pandas data frame with n_trials rows \n",
    "        \"\"\"\n",
    "        meta_flat = {'block_index':[], 'grid': [], 'card_a': [], 'trial_index': [], 'n_pairs': [], 'grid_dims': [], 'inv_grid': [],}\n",
    "        with open(subject_fn, 'rb') as f:\n",
    "            meta = pkl.load(f)\n",
    "        for block_index, block in enumerate(meta):\n",
    "            inv_grid = block['inv_grid']\n",
    "            grid_dims = block['grid_dims']\n",
    "            n_pairs = block['n_pairs']\n",
    "            grid = block['grid']\n",
    "            for trial_index, card_a in enumerate(block['trials']):\n",
    "                meta_flat['block_index'].append(block_index)\n",
    "                meta_flat['trial_index'].append(trial_index)\n",
    "                meta_flat['n_pairs'].append(n_pairs)\n",
    "                meta_flat['grid_dims'].append(grid_dims)\n",
    "                meta_flat['inv_grid'].append(inv_grid)\n",
    "                meta_flat['grid'].append(grid)\n",
    "                meta_flat['card_a'].append(card_a)\n",
    "        return pd.DataFrame(meta_flat)\n",
    "            \n",
    "            \n",
    "    def get_sync_times(f):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param f: MWKFile object \n",
    "        :return: \n",
    "            start_sync_t: array of trial start times\n",
    "            end_sync_t: array of trial end times              \n",
    "        \"\"\"\n",
    "        sync_events = f.get_events(codes=['sync'])\n",
    "        sync_events = np.asarray([[e.data, e.time] for e in sync_events])        \n",
    "        end_sync_t = sync_events[np.where(sync_events[:, 0] == TRIAL_END)[0], 1]\n",
    "        start_sync_t = sync_events[np.where(sync_events[:, 0] == TRIAL_INIT)[0], 1]\n",
    "        \n",
    "        start_sync_t = start_sync_t[:len(end_sync_t)]\n",
    "        \n",
    "        return start_sync_t, end_sync_t\n",
    "        \n",
    "    def get_dist(card_a, card_b, grid_dims):\n",
    "        \"\"\"\n",
    "        Returns spatial distance between two cards for given grid dimension         \n",
    "        :param grid: \n",
    "        :param card_a: \n",
    "        :param card_b: \n",
    "        :param grid_dims: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        card_a_loc = np.asarray([np.floor(card_a/grid_dims[1]), card_a%grid_dims[1]])\n",
    "        card_b_loc = np.asarray([np.floor(card_b/grid_dims[1]), card_b%grid_dims[1]])\n",
    "        return np.linalg.norm(card_a_loc - card_b_loc)\n",
    "    \n",
    "    def get_reaction_times(f, start_sync_t, end_sync_t):\n",
    "        N = len(start_sync_t)\n",
    "        rts = []\n",
    "        for trial in range(N):\n",
    "            start_t, end_t = np.long(start_sync_t[trial]), np.long(end_sync_t[trial])\n",
    "            sync = f.get_events(codes = ['sync'], time_range=[start_t, end_t])\n",
    "            sync = np.asarray([[e.data, e.time] for e in sync])                \n",
    "            flip_card_a = sync[np.where(sync[:, 0] == FLIP_CARD_A)[0], 1]\n",
    "            flip_card_b = sync[np.where(sync[:, 0] == FLIP_CARD_B)[0], 1]\n",
    "            rt = np.long(flip_card_b) - np.long(flip_card_a)\n",
    "            rts.append(rt/10**6)\n",
    "        return rts\n",
    "            \n",
    "    def get_scalar_data(f, codenames, start_sync_t, end_sync_t):\n",
    "        N = len(start_sync_t) \n",
    "        data_scalar = {'dur': [], 'card_a_img': [], 'card_b_img': [], 'dist': []}\n",
    "        meta = flatten_meta()\n",
    "        for c in codenames:\n",
    "            data_scalar[c] = []\n",
    "        for c in meta.columns:\n",
    "            if c != 'card_a':\n",
    "                data_scalar[c] = []\n",
    "        for trial in range(N):            \n",
    "            start_t, end_t = np.long(start_sync_t[trial]), np.long(end_sync_t[trial])\n",
    "            trial_events = f.get_events(codes = codenames, time_range=[start_t, end_t])\n",
    "            trial_events = np.asarray([[e.code, e.time, e.data] for e in trial_events])         \n",
    "            data_scalar['dur'].append((end_t - start_t)/10**6)        \n",
    "            for ci, c in enumerate(codenames): # currently this is only selecting card_b                \n",
    "                code = f.reverse_codec[c]\n",
    "                code_events = trial_events[np.where(trial_events[:, 0] == code)[0], 2]\n",
    "                data_scalar[c].append(code_events[0])                   \n",
    "            for ci, c in enumerate(meta.columns):\n",
    "                if c != 'card_a':\n",
    "                    data_scalar[c].append(meta.loc[trial][c])\n",
    "            data_scalar['card_a_img'].append(data_scalar['grid'][trial][data_scalar['card_a'][trial]])\n",
    "            data_scalar['card_b_img'].append(data_scalar['grid'][trial][data_scalar['card_b'][trial]])\n",
    "            data_scalar['dist'].append(get_dist(data_scalar['card_a'][trial], data_scalar['card_b'][trial], data_scalar['grid_dims'][trial]))\n",
    "            # verifying that card_a from meta and event stream line up\n",
    "            if meta.loc[trial]['card_a'] != data_scalar['card_a'][trial]:\n",
    "                print(\"Trial %d: meta and event stream are not aligned\" % trial)\n",
    "                break  \n",
    "        rts = get_reaction_times(f, start_sync_t, end_sync_t)        \n",
    "        data_scalar['rt'] = rts[:len(data_scalar['dur'])] ## TODO: remove indexing once you've fixed alignment prob w meta and event stream\n",
    "        \n",
    "        data_scalar = pd.DataFrame(data_scalar)\n",
    "        return data_scalar\n",
    "    \n",
    "    fpath = '/Users/%s/Documents/MWorks/Data' % username\n",
    "    f =  MWKFile('%s/%s' % (fpath, fn))\n",
    "    f.open()\n",
    "    codec = f.codec\n",
    "    codenames = ['card_b', 'card_a'] ## TODO: add trial_index with new set of data    \n",
    "    start_sync_t, end_sync_t = get_sync_times(f)\n",
    "    print('Collecting %d trials of data' % len(start_sync_t))\n",
    "    trial_dur_t = (end_sync_t - start_sync_t) / 10**6\n",
    "    print('Average trial duration: %f seconds' % np.mean(trial_dur_t))\n",
    "    data_scalar = get_scalar_data(f, codenames, start_sync_t, end_sync_t)\n",
    "    return data_scalar\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Collecting 296 trials of data\nAverage trial duration: 1.583154 seconds\nTrial 108: meta and event stream are not aligned\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "fn = \"apiccato-concentration-20200116-143523.mwk2\"\n",
    "data_scalar = unpack(fn, subject_fn)    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}