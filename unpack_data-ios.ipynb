{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/Library/Application Support/MWorks/Scripting/Python')\n",
    "from mworks.data import MWKFile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style \n",
    "import pandas as pd\n",
    "\n",
    "style.use('seaborn-poster') \n",
    "style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "username = 'apiccato'\n",
    "dir_path = '/Users/%s/PyCharmProjects/concentration/concentration-game-mworks' % username\n",
    "subject_id = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## sync times \n",
    "ITI = 1\n",
    "TRIAL_INIT = 2\n",
    "FLIP_CARD_A = 3\n",
    "FLIP_CARD_B = 4\n",
    "FEEDBACK = 5\n",
    "TRIAL_END = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Unpack():    \n",
    "    def __init__(self, fn):\n",
    "        fpath = '/Users/%s/Documents/MWorks/Data' % username\n",
    "        self.fn = fn        \n",
    "        self.f =  MWKFile('%s/%s' % (fpath, fn))\n",
    "        self.f.open()\n",
    "        self.codec = self.f.codec\n",
    "        self.codenames = ['card_b', 'card_a',  'grid', 'grid_dims', 'inv_grid', 'n_pairs', 'block_index'] ## 'ignore'] \n",
    "        self.start_sync_t, self.end_sync_t = self.get_sync_times()\n",
    "        self.n_trials = len(self.start_sync_t)\n",
    "        print('Collecting %d trials of data' % self.n_trials)\n",
    "        self.avg_trial_dur = (self.end_sync_t - self.start_sync_t) / 10**6\n",
    "        print('Average trial duration: %f seconds' % np.mean(self.avg_trial_dur))        \n",
    "        self.scalar = self.get_scalar_data()\n",
    "        self.analog = self.get_analog_data()\n",
    "\n",
    "                \n",
    "    def get_scalar_data(self):\n",
    "        data_scalar = {'dur': [], 'card_a_img': [], 'card_b_img': [], 'card_c': [], 'dist_a_b': [], 'dist_b_c': [], \n",
    "                       'success': [], 'failure': [], 'card_a_t': [], 'trial_index': []}\n",
    "        \n",
    "        for c in self.codenames:\n",
    "            data_scalar[c] = []\n",
    "\n",
    "        for trial in range(self.n_trials):            \n",
    "            start_t, end_t = np.long(self.start_sync_t[trial]), np.long(self.end_sync_t[trial])\n",
    "            trial_events = self.f.get_events(codes = self.codenames, time_range=[start_t, end_t])\n",
    "            trial_events = np.asarray([[e.code, e.time, e.data] for e in trial_events])         \n",
    "            # trial duration        \n",
    "            data_scalar['dur'].append((end_t - start_t)/10**6)        \n",
    "            for ci, c in enumerate(self.codenames): # currently this is only selecting card_b                \n",
    "                code = self.f.reverse_codec[c]\n",
    "                code_events = trial_events[np.where(trial_events[:, 0] == code)[0], 2]\n",
    "                data_scalar[c].append(code_events[0])                    \n",
    "            \n",
    "            card_a = data_scalar['card_a'][trial]\n",
    "            card_b = data_scalar['card_b'][trial]\n",
    "            grid = np.asarray(data_scalar['grid'][trial])\n",
    "            match = np.where(grid == grid[card_a])[0]            \n",
    "            card_c = match[match != card_a]    \n",
    "            \n",
    "            # TODO: remove this when success things are read in from mworks\n",
    "            data_scalar['success'].append(int((card_c == card_b)[0]))\n",
    "            data_scalar['failure'].append(int((card_c != card_b)[0]))\n",
    "            \n",
    "            data_scalar['card_c'].append(card_c[0])\n",
    "            \n",
    "            data_scalar['card_a_img'].append(data_scalar['grid'][trial][card_a])\n",
    "            data_scalar['card_b_img'].append(data_scalar['grid'][trial][card_b])\n",
    "            \n",
    "            # distance between locations of card a and b\n",
    "            data_scalar['dist_a_b'].append(self.get_dist(card_a, card_b, data_scalar['grid_dims'][trial]))\n",
    "            \n",
    "            # distance between locations of card b and correct card\n",
    "            data_scalar['dist_b_c'].append(self.get_dist(card_b, card_c, data_scalar['grid_dims'][trial]))\n",
    "            data_scalar['trial_index'].append(trial)\n",
    "        data_scalar['rt'] = self.get_reaction_times() \n",
    "        data_scalar['card_a_t'] = self.get_t(FLIP_CARD_A)\n",
    "\n",
    "        data_scalar = pd.DataFrame(data_scalar)\n",
    "        \n",
    "        return data_scalar\n",
    "    \n",
    "    def get_t(self, sync):\n",
    "\n",
    "        sync_events = self.f.get_events(codes = ['sync'])\n",
    "        sync_events = np.asarray([[e.code, e.time, e.data] for e in sync_events])\n",
    "        sync_events = sync_events[np.where(sync_events[:, 2] == sync)[0], 1]\n",
    "        return sync_events\n",
    "\n",
    "    \n",
    "    def get_analog_data(self):\n",
    "        data_analog = {'card': [], 'trial_index': [], 'time': [], 'block_index': [], 'flipped': []} \n",
    "        \n",
    "        for t in range(self.n_trials):\n",
    "            start_t, end_t = np.long(self.start_sync_t[t]), np.long(self.end_sync_t[t])\n",
    "            trial_events = self.f.get_events(codes=['sync'], time_range=[start_t, end_t])\n",
    "            trial_events = np.asarray([[e.code, e.time, e.data] for e in trial_events])\n",
    "            card_a_t = trial_events[np.where(trial_events[:, 2] == FLIP_CARD_A)[0], 1]\n",
    "            card_b_t = trial_events[np.where(trial_events[:, 2] == FLIP_CARD_B)[0], 1]\n",
    "            \n",
    "            data_analog['card'].append(self.scalar['card_a'][t])\n",
    "            data_analog['trial_index'].append(t)\n",
    "            data_analog['time'].append(card_a_t[0])\n",
    "            data_analog['block_index'].append(self.scalar['block_index'][t])\n",
    "            data_analog['flipped'].append(False)\n",
    "            \n",
    "            \n",
    "            if len(card_b_t) > 0:\n",
    "                data_analog['card'].append(self.scalar['card_b'][t])\n",
    "                data_analog['trial_index'].append(t)\n",
    "                data_analog['time'].append(card_b_t[0])         \n",
    "                data_analog['block_index'].append(self.scalar['block_index'][t])\n",
    "                data_analog['flipped'].append(True)\n",
    "                        \n",
    "        data_analog = pd.DataFrame(data_analog)    \n",
    "                                               \n",
    "        return data_analog\n",
    "    \n",
    "    def get_sync_times(self): \n",
    "        sync_events = self.f.get_events(codes=['sync'])\n",
    "        sync_events = np.asarray([[e.data, e.time] for e in sync_events])        \n",
    "        end_sync_t = sync_events[np.where(sync_events[:, 0] == TRIAL_END)[0], 1]\n",
    "        start_sync_t = sync_events[np.where(sync_events[:, 0] == TRIAL_INIT)[0], 1]\n",
    "        start_sync_t = start_sync_t[:len(end_sync_t)]\n",
    "        return start_sync_t, end_sync_t\n",
    "    \n",
    "    def get_dist(self, card_a, card_b, grid_dims): \n",
    "        card_a_loc = np.asarray([np.floor(card_a/grid_dims[1]), card_a%grid_dims[1]])\n",
    "        card_b_loc = np.asarray([np.floor(card_b/grid_dims[1]), card_b%grid_dims[1]])\n",
    "        return np.linalg.norm(card_a_loc - card_b_loc)\n",
    "    \n",
    "    def get_reaction_times(self):\n",
    "        rts = []\n",
    "        for trial in range(self.n_trials):\n",
    "            start_t, end_t = np.long(self.start_sync_t[trial]), np.long(self.end_sync_t[trial])\n",
    "            sync = self.f.get_events(codes = ['sync'], time_range=[start_t, end_t])\n",
    "            sync = np.asarray([[e.data, e.time] for e in sync])                \n",
    "            flip_card_a = sync[np.where(sync[:, 0] == FLIP_CARD_A)[0], 1]\n",
    "            flip_card_b = sync[np.where(sync[:, 0] == FLIP_CARD_B)[0], 1]                    \n",
    "            if len(flip_card_b) == 0:\n",
    "                flip_card_b = [flip_card_a]\n",
    "            rt = np.long(flip_card_b[0]) - np.long(flip_card_a[0])\n",
    "            rts.append(rt/10**6)\n",
    "        return rts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting 96 trials of data\n",
      "Average trial duration: 1.660950 seconds\n"
     ]
    }
   ],
   "source": [
    "fn = \"aidapiccato-concentration-ios-20200122-150945.mwk2\"\n",
    "unpack = Unpack(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysis:\n",
    "    def __init__(self, unpack):\n",
    "        self.scalar = unpack.scalar\n",
    "        self.analog = unpack.analog \n",
    "        \n",
    "    def get_last_t_card_df(self):\n",
    "        # series of times at which card_c was last seen by subject\n",
    "        times = pd.Series(self.scalar.apply(lambda t: self.get_last_t_card(t.card_c, t.trial_index, t.block_index), axis=1), name='card_c_t_last').to_frame()        \n",
    "        df = pd.concat([unpack.scalar, times], axis=1)[['card_c_t_last', 'card_a_t', 'success', 'block_index', 'card_a', 'card_c']]\n",
    "        df = df[~df.card_c_t_last.eq(-1)]\n",
    "        df['t_dist'] = df.card_a_t - df.card_c_t_last\n",
    "        df.t_dist = df.t_dist/10**6\n",
    "        df['time_bin'] = pd.cut(df.t_dist, bins=10)\n",
    "        \n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def get_last_t_card(self, card, trial_index, block_index):     \n",
    "        \"\"\"     \n",
    "        :param card: Card (location on grid)\n",
    "        :param trial: Trial before which to look for card flip\n",
    "        :param block_index: Index of block within which to look for card flipping\n",
    "        :return: Time at which card was last flipped prior to trial t\n",
    "        \"\"\"\n",
    "        last_t = self.analog[self.analog.card.eq(card) & self.analog.block_index.eq(block_index) & self.analog.trial_index.lt(trial_index)]\n",
    "        if len(last_t) > 0:\n",
    "            return last_t.iloc[-1].time\n",
    "        return -1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = Analysis(unpack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def prettify(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.title.set_style('italic')\n",
    "    ax.title.set_size(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concentration",
   "language": "python",
   "name": "concentration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
